---
title: "class1"
output: html_document
date: "2022-08-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
library(data.table)
library(nnet)
library(partykit)
library(randomForest)
library(tidyverse)
library(tree)
library(anytime)
library(dplyr)
library(lubridate)
library(ggthemes)


set.seed(100) # For reproducibility
```

# Import and prep

```{r}
df <- read_csv("outputs/df3.csv", show_col_types = FALSE)
df_all <- read_csv("outputs/df_all3.csv", show_col_types = FALSE)
df_train <- read_csv("outputs/df_train3.csv", show_col_types = FALSE)
df_val <- read_csv("outputs/df_val3.csv", show_col_types = FALSE)
df_test <- read_csv("outputs/df_test3.csv", show_col_types = FALSE)
df_all
```

# Train / val

```{r}
df_all = as.data.table(df_all)
df_all$month = as.factor(df_all$month)
df_all$weekdays = as.factor(df_all$weekdays)
#df_all[weekdays %in% c("Saturday",'Sunday'),weekend:=1]
#df_all[!(weekdays %in% c("Saturday",'Sunday')),weekend:=0]
df_all$weekend = as.factor(df_all$weekend)
#df_all$year = as.factor(df_all$year)
df_all$quarter = as.factor(df_all$quarter)
df_all$week = format(df_all$date, "%V")
df_all = as.data.frame(df_all)
df_all$week = as.numeric(df_all$week)
df_all$state = as.factor(df_all$state)
df_all

df = as.data.table(df)
df$month = as.factor(df$month)
df$weekdays = as.factor(df$weekdays)
df$weekend = as.factor(df$weekend)
df$quarter = as.factor(df$quarter)
df$week = format(df$date, "%V")
df = as.data.frame(df)
df$week = as.numeric(df$week)
df$state = as.factor(df$state)
df

df_train = as.data.table(df_train)
df_train$month = as.factor(df_train$month)
df_train$weekdays = as.factor(df_train$weekdays)
df_train$weekend = as.factor(df_train$weekend)
df_train$quarter = as.factor(df_train$quarter)
df_train$week = format(df_train$date, "%V")
df_train = as.data.frame(df_train)
df_train$week = as.numeric(df_train$week)
df_train$state = as.factor(df_train$state)
df_train


df_val = as.data.table(df_val)
df_val$month = as.factor(df_val$month)
df_val$weekdays = as.factor(df_val$weekdays)
df_val$weekend = as.factor(df_val$weekend)
df_val$quarter = as.factor(df_val$quarter)
df_val$week = format(df_val$date, "%V")
df_val = as.data.frame(df_val)
df_val$week = as.numeric(df_val$week)
df_val$state = as.factor(df_val$state)
df_val

df_test = as.data.table(df_test)
df_test$month = as.factor(df_test$month)
df_test$weekdays = as.factor(df_test$weekdays)
df_test$weekend = as.factor(df_test$weekend)
df_test$quarter = as.factor(df_test$quarter)
df_test$week = format(df_test$date, "%V")
df_test = as.data.frame(df_test)
df_test$week = as.numeric(df_test$week)
df_test$state = as.factor(df_test$state)
df_test
```

```{r}
df_all$mday <- df_all$day 
df_all$wday <- df_all$weekdays
df_all$hr <- df_all$Hour
df_all$qrtr <- df_all$quarter
df_all$mnth <- df_all$month
df_all$wend <- df_all$weekend
df_all$rmean <- df_all$rolling_mean
df_all$rmed <- df_all$rolling_median
df_all$rskew <- df_all$rolling_skewness
df_all$rkurt <- df_all$rolling_kurtosis
df_all$rstd <- df_all$rolling_std
df_all$rslope <- df_all$rolling_slope
df_all$gas <- df_all$kwh
df_all$l1 <- df_all$lag_1
df_all$l2 <- df_all$lag_2
df_all$l3 <- df_all$lag_3
df_all$l4 <- df_all$lag_4
df_all$l5 <- df_all$lag_5

df$mday <- df$day 
df$wday <- df$weekdays
df$hr <- df$Hour
df$qrtr <- df$quarter
df$mnth <- df$month
df$wend <- df$weekend
df$rmean <- df$rolling_mean
df$rmed <- df$rolling_median
df$rskew <- df$rolling_skewness
df$rkurt <- df$rolling_kurtosis
df$rstd <- df$rolling_std
df$rslope <- df$rolling_slope
df$gas <- df$kwh
df$l1 <- df$lag_1
df$l2 <- df$lag_2
df$l3 <- df$lag_3
df$l4 <- df$lag_4
df$l5 <- df$lag_5

df_train$mday <- df_train$day 
df_train$wday <- df_train$weekdays
df_train$hr <- df_train$Hour
df_train$qrtr <- df_train$quarter
df_train$mnth <- df_train$month
df_train$wend <- df_train$weekend
df_train$rmean <- df_train$rolling_mean
df_train$rmed <- df_train$rolling_median
df_train$rskew <- df_train$rolling_skewness
df_train$rkurt <- df_train$rolling_kurtosis
df_train$rstd <- df_train$rolling_std
df_train$rslope <- df_train$rolling_slope
df_train$gas <- df_train$kwh
df_train$l1 <- df_train$lag_1
df_train$l2 <- df_train$lag_2
df_train$l3 <- df_train$lag_3
df_train$l4 <- df_train$lag_4
df_train$l5 <- df_train$lag_5

df_val$mday <- df_val$day 
df_val$wday <- df_val$weekdays
df_val$hr <- df_val$Hour
df_val$qrtr <- df_val$quarter
df_val$mnth <- df_val$month
df_val$wend <- df_val$weekend
df_val$rmean <- df_val$rolling_mean
df_val$rmed <- df_val$rolling_median
df_val$rskew <- df_val$rolling_skewness
df_val$rkurt <- df_val$rolling_kurtosis
df_val$rstd <- df_val$rolling_std
df_val$rslope <- df_val$rolling_slope
df_val$gas <- df_val$kwh
df_val$l1 <- df_val$lag_1
df_val$l2 <- df_val$lag_2
df_val$l3 <- df_val$lag_3
df_val$l4 <- df_val$lag_4
df_val$l5 <- df_val$lag_5

df_test$mday <- df_test$day 
df_test$wday <- df_test$weekdays
df_test$hr <- df_test$Hour
df_test$qrtr <- df_test$quarter
df_test$mnth <- df_test$month
df_test$wend <- df_test$weekend
df_test$rmean <- df_test$rolling_mean
df_test$rmed <- df_test$rolling_median
df_test$rskew <- df_test$rolling_skewness
df_test$rkurt <- df_test$rolling_kurtosis
df_test$rstd <- df_test$rolling_std
df_test$rslope <- df_test$rolling_slope
df_test$gas <- df_test$kwh
df_test$l1 <- df_test$lag_1
df_test$l2 <- df_test$lag_2
df_test$l3 <- df_test$lag_3
df_test$l4 <- df_test$lag_4
df_test$l5 <- df_test$lag_5
```

```{r}
all <- subset(df_all, select = c('hr','yday','mday','wday','wend','week','mnth','qrtr','t','gas',
                                   'l1','l2','l3','l4','l5','rmean','rmed','rstd','rslope','rskew','rkurt',
                                   'state'))

train <- subset(df_train, select = c('hr','yday','mday','wday','wend','week','mnth','qrtr','t','gas',
                                   'l1','l2','l3','l4','l5','rmean','rmed','rstd','rslope','rskew','rkurt',
                                   'state'))
val <- subset(df_val, select = c('hr','yday','mday','wday','wend','week','mnth','qrtr','t','gas',
                                   'l1','l2','l3','l4','l5','rmean','rmed','rstd','rslope','rskew','rkurt',
                                   'state'))
test <- subset(df_test, select = c('hr','yday','mday','wday','wend','week','mnth','qrtr','t','gas',
                                   'l1','l2','l3','l4','l5','rmean','rmed','rstd','rslope','rskew','rkurt',
                                   'state'))


dff <- subset(df, select = c('hr','yday','mday','wday','wend','week','mnth','qrtr','t','gas',
                                   'l1','l2','l3','l4','l5','rmean','rmed','rstd','rslope','rskew','rkurt'))


# train <- subset(df_train, select = c('t','yday','month','day','weekend','weekdays','week','Hour', 'quarter',
#                                      'kwh','lag_1','lag_2','lag_3','lag_4','lag_5','rolling_mean','rolling_median',
#                                      'rolling_skewness','rolling_kurtosis','rolling_std','rolling_slope',
#                                      'state'))
# 
# val <- subset(df_val, select = c('t','yday','month','day','weekend','weekdays','week','Hour','quarter',
#                                      'kwh','lag_1','lag_2','lag_3','lag_4','lag_5','rolling_mean','rolling_median',
#                                      'rolling_skewness','rolling_kurtosis','rolling_std','rolling_slope',
#                                      'state'))
# 
# test <- subset(df_test, select = c('t','yday','month','day','weekend','weekdays','week','Hour','quarter',
#                                      'kwh','lag_1','lag_2','lag_3','lag_4','lag_5','rolling_mean','rolling_median',
#                                      'rolling_skewness','rolling_kurtosis','rolling_std','rolling_slope',
#                                      'state'))

train
val
test
```

```{r}
library(visdat)

all %>% sample_frac(0.1) %>% vis_dat()
#all %>% sample_frac(0.1) %>% vis_miss( ,sort_miss = TRUE)
```

```{r}
ggsave('feat1.png', plot = last_plot(), dpi = 800, width = 8, height = 2)
```

```{r}
#Separate X and Y (for validation)
X_train <- train %>% 
  select(!contains(c("state")))
X_val <- val %>% 
  select(!contains(c("state")))
X_test <- test %>% 
  select(!contains(c("state")))

y_train <- train %>% select('state')
y_val <- val %>% select('state')
y_test <- test %>% select('state')

X_train
y_train

X_val
y_val

X_test
y_test
```

```{r}
mape <- function(actual,pred){
  mape <- mean(abs((actual - pred)/actual))*100
  return (mape)
}
```

# SVM

```{r}
#library(e1071)
#library(rpart)

## svm
#svm <- svm(state ~ ., data = train, cost = 16, gamma = 2, kernel = 'radial', type = 'C-classification')
#svm.pred  <- svm %>% predict(X_val)
#summary(svm.model)
```

# Logistic Regression

#### train

```{r}
# logistic
log <- multinom(state ~ ., data = train)
log_pred_val <- log %>% predict(X_val)

mean(log_pred_val == y_val$state)
```

```{r}
log_imp <- varImp(log)
print(log)
summary(log)
```

```{r}
actual <- y_val$state
pred <- log_pred_val

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

#### test

```{r}
log_pred_test <- log %>% predict(X_test)
mean(log_pred_test == y_test$state)
```

```{r}
actual <- y_test$state
pred <- log_pred_test

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

```{r}
test %>%
  ggplot(aes(x = rslope,
             y = state)) +
  geom_point(alpha = .4) +
  geom_smooth(method = "lm") +
  labs(y = "Default (1 = yes, 0 = no)",
       title = "Default outcome by balance") +
  theme_minimal()
```

# Decision Tree 1

[http://www.science.smith.edu/\~jcrouser/SDS293/labs/lab14-r.html#:\~:text=which%20is%20deviance%20.-,The%20cv.,equation%20we%20saw%20in%20lecture).](http://www.science.smith.edu/~jcrouser/SDS293/labs/lab14-r.html#:~:text=which%20is%20deviance%20.-,The%20cv.,equation%20we%20saw%20in%20lecture).)

```{r}
library(tree)
library(ISLR)
library(dplyr)
library(ggplot2)
```

```{r}
tree = tree(state ~ ., train)
summary(tree)
```

```{r}
plot(tree)
text(tree, pretty = 0)
```

```{r}
tree
```

Pruning

```{r}
set.seed(3)
cv_tree = cv.tree(tree, FUN = prune.misclass)
```

```{r}
plot(cv_tree$size, cv_tree$dev, type = "b")
```

```{r}
prune_tree = prune.misclass(tree, best = 3)
plot(prune_tree)
text(prune_tree, pretty = 0)
```

#### train

```{r}
tree_pred_val <- prune_tree %>% predict(X_val, type = "class")


mean(tree_pred_val == y_val$state)
```

```{r}
actual <- y_val$state
pred <- tree_pred_val

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

#### test

```{r}
tree_pred_test <- prune_tree %>% predict(X_test, type = "class")
mean(tree_pred_test == y_test$state)
```

```{r}
actual <- y_test$state
pred <- tree_pred_test

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

# Decision Tree 2

#### train

```{r}
fitControl <- trainControl(method = "cv", number = 10)
#fitControl <- y_val$state

dtree <- train(
  state ~ ., data = train, 
  method = "ctree", trControl = fitControl
)
```

```{r}
# Without temperature - Train
#dtree <- ctree(state ~ ., data = train)
dtree_pred_val <- dtree %>% predict(X_val)

mean(dtree_pred_val == y_val$state)
```

```{r}
suppressWarnings(library(kernlab))
suppressWarnings(library(tree))
suppressWarnings(library(randomForest))
suppressWarnings(library(beepr)) # try it! beep()
suppressWarnings(library(pROC))

#cv.prune <- cv.tree(dtree, FUN = prune.misclass)
#plot(cv.prune$size, cv.prune$dev, pch = 20, col = "red", type = "b",
    # main = "Decision tree: Cross validation to find optimal size of tree",
    # xlab = "Size of tree", ylab = "Misclassifications")
```

```{r}
#summary(dtree)
#print(dtree)
```

```{r}
actual <- y_val$state
pred <- dtree_pred_val

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

#### test

```{r}
dtree_pred_test <- dtree %>% predict(X_test)
mean(dtree_pred_test == y_test$state)
```

```{r}
actual <- y_test$state
pred <- dtree_pred_test

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

```{r}
df$pred <- dtree %>% predict(dff)

```

```{r}
write.csv(df,"outputs/df.csv", row.names = FALSE)
```

# Random Forest 1

```{r}
library(randomForest)
set.seed(1)
bag = randomForest(state~., 
                          data = train, 
                          mtry = 21, 
                          importance = TRUE)
bag
```

```{r}
X_val1 <- rbind(X_train[1, ] , X_val)
X_val1 <- X_val1[-1,]

bag_pred_val = predict(bag, 
                          newdata = X_val1)

ggplot() + 
    geom_point(aes(x = y_val$state, y = bag_pred_val)) +
    geom_abline()
```

```{r}
bag_25 = randomForest(state~., data =  train, mtry = 10, ntree = 500)
bag_25_pred_val = predict(bag_25, newdata = X_val1)
#mean((bag_25_pred_val - y_val$state)^2)
```

```{r}
set.seed(1)
rf1 = randomForest(state~., 
                         data = train, 
                         mtry = 6, 
                         importance = TRUE)

rf1_pred_val = predict(rf1,newdata = X_val1)

mean((rf1_pred_val - y_val$state)^2)
```

```{r}
importance(rf1)

```

```{r}
varImpPlot(rf1)

```

```{r}
actual <- y_val$state
pred <- rf1_pred_val

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

```{r}
bag_25 = randomForest(state~., data =  train, mtry = 21, ntree = 500)
bag_25_pred_test = predict(bag_25, newdata = X_test)
```

```{r}
rf1_pred_test = predict(rf1, newdata = X_test)
```

```{r}
actual <- y_test$state
pred <- rf1_pred_test

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

# Random Forest 2

#### train

```{r}
X_val1 <- rbind(X_train[1, ] , X_val)
X_val1 <- X_val1[-1,]
```

```{r}
rf <- randomForest(state ~ ., data = train, ntree=300, importance=TRUE)
rf_pred_val <- rf %>% predict(X_val1)

mean(rf_pred_val == y_val$state)
```

```{r}
plot(rf$err.rate[,1], type = "l", lwd = 3, col = "blue",
     main = "Bagging: OOB estimate of error rate",
     xlab = "Number of Trees", ylab = "OOB error rate")
```

```{r}
ggsave('class1.png', plot = last_plot(), dpi = 800, width = 8, height = 2)
```

```{r}
print(rf)
```

```{r}
importance(rf,scale=TRUE)
varImpPlot(rf, cex=0.8,  main = "RF: Variable importance")
```

```{r}
actual <- y_val$state
pred <- rf_pred_val

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

#### test

```{r}
rf_pred_test <- rf %>% predict(X_test)
mean(rf_pred_test == y_test$state)
```

```{r}
actual <- y_test$state
pred <- rf_pred_test

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

```{r}
rf.pred.prob <- predict(rf ,
                        subset(test, select = -state),
                        type = "prob")

plot.roc(test$state,
         rf.pred.prob[,1], col = "blue",
         lwd = 3, print.auc = TRUE, print.auc.y = 0.3,
         main = "ROC-AUC of RF")
## Setting levels: control = nonspam, case = spam
## Setting direction: controls > cases

#legend(x = 0.6, y = 0.8, lwd = 1)
```

# XGBoost

#### reformat data

```{r}
library(Matrix)
sparse_matrix1 <- sparse.model.matrix(state ~ ., data = train)[,-1]
sparse_matrix2 <- sparse.model.matrix(state ~ ., data = val)[,-1]
sparse_matrix3 <- sparse.model.matrix(state ~ ., data = test)[,-1]
```

```{r}
sparse_matrix3
```

```{r}

label <- as.numeric(y_train$state)-1
train_matrix <- xgb.DMatrix(sparse_matrix1, label = label)

label <- as.numeric(y_val$state)-1
val_matrix <- xgb.DMatrix(sparse_matrix2, label = label)

label <- as.numeric(y_test$state)-1
test_matrix <- xgb.DMatrix(sparse_matrix3, label = label)
```

#### train

```{r}
xgb_params <- list("objective"="binary:logistic","eval_metric"="logloss", 
                   max_depth = 5, learning_rate = 0.0003)
watchlist <- list(train=train_matrix, test=val_matrix)


#XGB Model
xgb <- xgb.train(params = xgb_params, data = train_matrix, gamma=10,
                       nrounds = 5500, watchlist = watchlist)
```

```{r}
importance_matrix <- xgb.importance(model = xgb)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
```

```{r}
summary(xgb)
```

```{r}
xgb_pred_train = predict(xgb, train_matrix)
print(head(xgb_pred_train))
```

```{r}
xgb_pred_train <- as.numeric(xgb_pred_train > 0.5)
print(head(xgb_pred_train))
```

```{r}
xgb_pred_train <- as.factor(xgb_pred_train)

actual <- y_train$state
pred <- xgb_pred_train

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

```{r}
#xgb.pred = predict(xgb,test_matrix,reshape=T)
#xgb.pred = as.data.frame(xgb.pred)
#colnames(xgb.pred) = "state"
#xgb.pred
```

#### test

```{r}
xgb_pred_test = predict(xgb, test_matrix)
print(head(xgb_pred_test))
```

```{r}
xgb_pred_test <- as.numeric(xgb_pred_test > 0.5)
print(head(xgb_pred_test))
```

```{r}
xgb_pred_test <- as.factor(xgb_pred_test)

actual <- y_test$state
pred <- xgb_pred_test

confusionMatrix(pred, actual, mode = "everything", positive="1")
```

## XGBoost 2

```{r}
# libraries we're going to use
library(xgboost) # for xgboost
library(tidyverse) # general utility functions
set.seed(1234)

```

```{r}
# training data
#train_data <- X_train[1:]
#train_labels <- y_train[1:]

# testing data
#test_data <- diseaseInfo_matrix[-(1:numberOfTrainingSamples),]
#test_labels <- diseaseLabels[-(1:numberOfTrainingSamples)]
```

```{r}
X_train_m <- data.matrix(X_train)
y_train_m <- data.matrix(y_train)-1
X_val_m <- data.matrix(X_val)
y_val_m <- data.matrix(y_val)-1
X_test_m <- data.matrix(X_test)
y_test_m <- data.matrix(y_test)-1
```

```{r}
# put our testing & training data into two seperates Dmatrixs objects
dtrain <- xgb.DMatrix(data = X_train_m, label= y_train_m)
dval <- xgb.DMatrix(data = X_val_m, label= y_val_m)
dtest <- xgb.DMatrix(data = X_test_m, label= y_test_m)
```

```{r}
# train a model using our training data
model <- xgboost(data = dtrain, # the data   
                 nround = 2, # max number of boosting iterations
                 objective = "binary:logistic")  # the objective function
```

```{r}
# generate predictions for our held-out testing data
pred <- predict(model, dtest)

# get & print the classification error
err <- mean(as.numeric(pred > 0.5) != y_test_m)
print(paste("test-error=", err))
```

```{r}
# train an xgboost model
model_tuned <- xgboost(data = dtrain, # the data           
                 max.depth = 3, # the maximum depth of each decision tree
                 nround = 2, # max number of boosting iterations
                 objective = "binary:logistic") # the objective function 

# generate predictions for our held-out testing data
pred <- predict(model_tuned, dtest)

# get & print the classification error
err <- mean(as.numeric(pred > 0.5) != y_test_m)
print(paste("test-error=", err))
```

```{r}
# get the number of negative & positive cases in our data
negative_cases <- sum(y_train_m == FALSE)
postive_cases <- sum(y_train_m == TRUE)

# train a model using our training data
model_tuned <- xgboost(data = dtrain, # the data           
                 max.depth = 3, # the maximum depth of each decision tree
                 nround = 10, # number of boosting rounds
                 early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
                 objective = "binary:logistic", # the objective function
                 scale_pos_weight = negative_cases/postive_cases) # control for imbalanced classes

# generate predictions for our held-out testing data
pred <- predict(model_tuned, dtest)

# get & print the classification error
err <- mean(as.numeric(pred > 0.5) != y_test_m)
print(paste("test-error=", err))
```

```{r}
# train a model using our training data
model_tuned <- xgboost(data = dtrain, # the data           
                 max.depth = 3, # the maximum depth of each decision tree
                 nround = 10, # number of boosting rounds
                 early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
                 objective = "binary:logistic", # the objective function
                 scale_pos_weight = negative_cases/postive_cases, # control for imbalanced classes
                 gamma = 1) # add a regularization term

# generate predictions for our held-out testing data
pred <- predict(model_tuned, dtest)

# get & print the classification error
err <- mean(as.numeric(pred > 0.5) != y_test_m)
print(paste("test-error=", err))
```
